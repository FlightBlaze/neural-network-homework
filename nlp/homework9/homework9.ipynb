{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание\n",
    "\n",
    "Разобраться с моделькой генерации текста, собрать самим или взять датасет с вебинара и обучить генератор текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_PATH = 'evgenyi_onegin.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(TEXT_PATH, 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "dist = FreqDist(corpus)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {k: v for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [vocabulary[token] for token in corpus if token in vocabulary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n",
      "Александр\n",
      "Сергеевич\n",
      "Пушкин\n",
      "Евгений\n",
      "Онегин\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-03 19:57:27.640559: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-09-03 19:57:27.641022: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(data)//(seq_length+1)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "\n",
    "for i in dataset.take(5):\n",
    "    print(idx2word[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Александр Сергеевич Пушкин Евгений Онегин Роман в стихах Не мысля гордый свет забавить , Вниманье дружбы возлюбя , Хотел бы я тебе представить Залог достойнее тебя , Достойнее души прекрасной , Святой исполненной мечты , Поэзии живой и ясной , Высоких дум и простоты ; Но так и быть - рукой пристрастной Прими собранье пестрых глав , Полусмешных , полупечальных , Простонародных , идеальных , Небрежный плод моих забав , Бессонниц , легких вдохновений , Незрелых и увядших лет , Ума холодных наблюдений И сердца горестных замет . ГЛАВА ПЕРВАЯ И жить торопится и чувствовать спешит . Кн . Вяземский .'\n",
      "\"I `` Мой дядя самых честных правил , Когда не в шутку занемог , Он уважать себя заставил И лучше выдумать не мог . Его пример другим наука ; Но , боже мой , какая скука С больным сидеть и день и ночь , Не отходя ни шагу прочь ! Какое низкое коварство Полуживого забавлять , Ему подушки поправлять , Печально подносить лекарство , Вздыхать и думать про себя : Когда же черт возьмет тебя ! '' II Так думал молодой повеса , Летя в пыли на почтовых , Всевышней волею Зевеса Наследник всех своих родных . Друзья Людмилы и Руслана\"\n",
      "\"! С героем моего романа Без предисловий , сей же час Позвольте познакомить вас : Онегин , добрый мой приятель , Родился на брегах Невы , Где , может быть , родились вы Или блистали , мой читатель ; Там некогда гулял и я : Но вреден север для меня { 1 } . III Служив отлично благородно , Долгами жил его отец , Давал три бала ежегодно И промотался наконец . Судьба Евгения хранила : Сперва Madame за ним ходила , Потом Monsieur ее сменил . Ребенок был резов , но мил . Monsieur l'Abbe , француз убогой , Чтоб\"\n",
      "'не измучилось дитя , Учил его всему шутя , Не докучал моралью строгой , Слегка за шалости бранил И в Летний сад гулять водил . IV Когда же юности мятежной Пришла Евгению пора , Пора надежд и грусти нежной , Monsieur прогнали со двора . Вот мой Онегин на свободе ; Острижен по последней моде , Как dandy { 2 } лондонский одет - И наконец увидел свет . Он по-французски совершенно Мог изъясняться и писал ; Легко мазурку танцевал И кланялся непринужденно ; Чего ж вам больше ? Свет решил , Что он умен и очень мил . V Мы'\n",
      "'все учились понемногу Чему-нибудь и как-нибудь , Так воспитаньем , слава богу , У нас немудрено блеснуть . Онегин был по мненью многих ( Судей решительных и строгих ) Ученый малый , но педант : Имел он счастливый талант Без принужденья в разговоре Коснуться до всего слегка , С ученым видом знатока Хранить молчанье в важном споре И возбуждать улыбку дам Огнем нежданных эпиграмм . VI Латынь из моды вышла ныне : Так , если правду вам сказать , Он знал довольно по-латыне , Чтоб эпиграфы разбирать , Потолковать об Ювенале , В конце письма поставить vale , Да помнил ,'\n"
     ]
    }
   ],
   "source": [
    "sequences = dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(' '.join([idx2word[idx] for idx in item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int32, name=None), TensorSpec(shape=(64, 100), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 15000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocabulary)\n",
    "EMBEDDING_DIM = 256\n",
    "RNN_UNITS = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNgenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, batch_size):\n",
    "        super(RNNgenerator, self).__init__()\n",
    "        \n",
    "        self.emb = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "                                 \n",
    "        self.gru1 = tf.keras.layers.GRU(RNN_UNITS,\n",
    "                            return_sequences=True,\n",
    "                            recurrent_initializer='glorot_uniform')\n",
    "        self.gru2 = tf.keras.layers.GRU(RNN_UNITS,\n",
    "                            return_sequences=True,\n",
    "                            recurrent_initializer='glorot_uniform')\n",
    "                           \n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, x):\n",
    "        emb_x = self.emb(x)\n",
    "        x1 = self.gru1(emb_x)\n",
    "        x = x1\n",
    "        for _ in range(3):\n",
    "            x = self.gru2(x)\n",
    "        #x = self.gru1(x)\n",
    "        x = (x + x1)/2\n",
    "        return self.fc(x)\n",
    "\n",
    "model = RNNgenerator(VOCAB_SIZE, EMBEDDING_DIM, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-03 19:56:23.915820: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-03 19:56:24.251860: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-03 19:56:24.711883: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-03 19:56:25.999758: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-03 19:56:29.560010: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-03 19:56:31.065791: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-03 19:56:36.658172: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__!!!__\n",
    "\n",
    "Я в истерике, у меня модель не хочет обучаться, вместо этого строчит `Plugin optimizer for device_type GPU is enabled`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPERATURE = 0.1\n",
    "\n",
    "def generate_text(model, start_str):\n",
    "    num_iter = 80\n",
    "    inputs = tf.expand_dims([vocabulary[tok] for tok in word_tokenize(start_str)], 0)\n",
    "    generated_text = []\n",
    "    model.reset_states()\n",
    "    for i in range(num_iter):\n",
    "        pred = model(inputs)\n",
    "        pred = tf.squeeze(pred, 0)\n",
    "        pred /= TEMPERATURE\n",
    "        predicted_id = tf.random.categorical(pred, num_samples=1)[-1, 0].numpy()\n",
    "        inputs = tf.expand_dims([predicted_id], 0)\n",
    "        generated_text.append(idx2word[predicted_id])\n",
    "    return start_str + ' '.join(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "И вот идет уженаших Прослыть небесной необузданных грудь Байрона но прикрасой везде тихий чувству Полужуравль мой А обуза склад вынулось жужжит замирать элегии зале Эву минувших привлечь высоком Берет неслись трюфли Прелестным опасной мадригал приказала фальшивя согласно Онегину Дошло Крестьянин глубоко созрел тоске французский чужеземные верхом блаженство злых смелый приличию тревожить ствол пушистый Умел построже француз Qu'ecrirez-vous ободренный Невольно вежды почти 36 Устремлены обманы распущенные задремал волоса ведет инвалид родителей ввинченный игрушкой Взяв окном устарела спаситель заманчивой Надолго Смелей запущенный пойдет забав слеза\n"
     ]
    }
   ],
   "source": [
    "gen_text = generate_text(model, start_str=u'И вот идет уже')\n",
    "print(gen_text)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3af7e179898fb99d78969cca94508015726394a06defd0be323cbf435423c41d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('nn': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
