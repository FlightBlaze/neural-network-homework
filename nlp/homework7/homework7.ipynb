{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –î–æ–º–∞—à–Ω—è—è —Ä–∞–±–æ—Ç–∞\n",
    "–ë–µ—Ä–µ–º –æ—Ç—ã–∑—ã–≤—ã –∑–∞ –ª–µ—Ç–æ (–∏–∑ –∞—Ä—Ö–∏–≤–∞ —Å –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏ –∏–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–Ω—è—Ç–∏—è)\n",
    "1. –£—á–∏–º conv —Å–µ—Ç—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "2. –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å 2-–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞ —Å–µ—Ç–æ—á–µ–∫ \n",
    "\n",
    "2.1 –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å tf.keras.layers.Embedding –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –≤–∑—è—Ç—å –∫ –ø—Ä–∏–º–µ—Ä—É —Å https://rusvectores.org/ru/\n",
    "\n",
    "2.2 –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–π tf.keras.layers.Embedding –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–Ω—É —Ç–æ –µ—Å—Ç—å –≤–∞–º –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞—Ç—å —Å –≤–µ—Å–∞–º–∏)\n",
    "\n",
    "–°—Ä–∞–≤–Ω–∏—Ç—å –¥–≤–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏ –∏ –∫–æ–≥–¥–∞ tf.keras.layers.Embedding –æ–±—É—á–∞–µ—Ç—Å—è —Å—Ä–∞–∑—É —Å–æ –≤—Å–µ–π —Å–µ—Ç–æ—á–∫–æ–π, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ª—É—á—à–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in /opt/homebrew/Caskroom/miniforge/base/envs/nn/lib/python3.10/site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('–æ—Ç–∑—ã–≤—ã –∑–∞ –ª–µ—Ç–æ.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>–í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–æ –≤—Å–µ</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>–°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å—ë —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º üëçüëçüëç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>–£ –º–µ–Ω—è —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ —á–µ—Ç–∫–æ. –í –æ—Ç–ª–∏—á–∏–∏ –æ—Ç –±–∞–Ω–∫–æ–º...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å –≤—Å–µ —Ö–æ—Ä–æ—à–æüëç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å–µ –æ–∫!</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –∫—Ä–æ–º–µ —Ç–æ–≥–æ —á—Ç–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –Ω–µ–ª—å...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>–ù–µ —Å—Ç–∞—Ä—Ç—É–µ—Ç –±–µ–∑ –¥–æ—Å—Ç—É–ø–∞ –∫ gps, sms, –∑–≤–æ–Ω–∫–∞–º –∏ ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–æ, –ø–æ–¥–≤–∏—Å–∞–Ω–∏...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rating                                            Content        Date\n",
       "0        5                                     It just works!  2017-08-14\n",
       "1        4  –í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...  2017-08-14\n",
       "2        5                                        –û—Ç–ª–∏—á–Ω–æ –≤—Å–µ  2017-08-14\n",
       "3        5  –°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...  2017-08-14\n",
       "4        5                     –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.  2017-08-14\n",
       "5        5                                –í—Å—ë —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º üëçüëçüëç  2017-08-14\n",
       "6        5                          –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.  2017-08-14\n",
       "7        5                                     –í—Å–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç  2017-08-14\n",
       "8        5  –£ –º–µ–Ω—è —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ —á–µ—Ç–∫–æ. –í –æ—Ç–ª–∏—á–∏–∏ –æ—Ç –±–∞–Ω–∫–æ–º...  2017-08-14\n",
       "9        5                                  –û—á–µ–Ω—å –≤—Å–µ —Ö–æ—Ä–æ—à–æüëç  2017-08-14\n",
       "10       5                                            –í—Å–µ –æ–∫!  2017-08-14\n",
       "11       5  –í—Å–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –∫—Ä–æ–º–µ —Ç–æ–≥–æ —á—Ç–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –Ω–µ–ª—å...  2017-08-14\n",
       "12       2  –ù–µ —Å—Ç–∞—Ä—Ç—É–µ—Ç –±–µ–∑ –¥–æ—Å—Ç—É–ø–∞ –∫ gps, sms, –∑–≤–æ–Ω–∫–∞–º –∏ ...  2017-08-14\n",
       "13       5  –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–æ, –ø–æ–¥–≤–∏—Å–∞–Ω–∏...  2017-08-14\n",
       "14       5                                       –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ  2017-08-14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    14586\n",
       "1     2276\n",
       "4     2138\n",
       "3      911\n",
       "2      748\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20659, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import pymorphy2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['—Å—ä–µ—Å—Ç—å', '–µ—â—ë', '–º—è–≥–∫–∏–π', '—Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π', '–±—É–ª–∫–∞', '–≤—ã–ø–∏—Ç—å', '—á–∞–π']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "stopwords_list = stopwords.words('russian')\n",
    "punct = set(punctuation)\n",
    "\n",
    "def tokenize_and_preprocess(text):\n",
    "    if type(text) is not str:\n",
    "        return []\n",
    "    # txt = \"\".join(c for c in text if c not in punct)\n",
    "    txt = text\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\s–Ω–µ\", \"–Ω–µ\", txt)\n",
    "    words = word_tokenize(txt)\n",
    "    lemmas = [morph.parse(w)[0].normal_form for w in words]\n",
    "    return [w for w in lemmas if not w in stopwords_list and w.isalpha()]\n",
    "\n",
    "tokenize_and_preprocess('–°—ä–µ—à—å –µ—â–µ —ç—Ç–∏—Ö –º—è–≥–∫–∏—Ö —Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–∏—Ö –±—É–ª–æ–∫, –¥–∞ –≤—ã–ø–µ–π –∂–µ —á–∞—é!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "      <th>Prepared_Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>[it, just, works]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>–í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>[—Ü–µ–ª–æ–µ, —É–¥–æ–±–Ω–æ–Ω–æ–π, –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, –º–∏–Ω—É—Å, —Ö–æ—Ç–µ—Ç—å, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–æ –≤—Å–µ</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>[–æ—Ç–ª–∏—á–Ω–æ, –≤—Å—ë]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>–°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>[—Å—Ç–∞—Ç—å, –∑–∞–≤–∏—Å–∞—Ç—å, —Ä–∞–±–æ—Ç–∞, –∞–Ω—Ç–∏–≤–∏—Ä—É—Å, –¥–∞–ª—ë–∫–∏–π, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>[–æ—á–µ–Ω—å, —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞—Ç—å, –±—ã—Å—Ç—Ä–æ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date  \\\n",
       "0       5                                     It just works!  2017-08-14   \n",
       "1       4  –í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...  2017-08-14   \n",
       "2       5                                        –û—Ç–ª–∏—á–Ω–æ –≤—Å–µ  2017-08-14   \n",
       "3       5  –°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...  2017-08-14   \n",
       "4       5                     –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.  2017-08-14   \n",
       "\n",
       "                                    Prepared_Content  \n",
       "0                                  [it, just, works]  \n",
       "1  [—Ü–µ–ª–æ–µ, —É–¥–æ–±–Ω–æ–Ω–æ–π, –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, –º–∏–Ω—É—Å, —Ö–æ—Ç–µ—Ç—å, ...  \n",
       "2                                     [–æ—Ç–ª–∏—á–Ω–æ, –≤—Å—ë]  \n",
       "3  [—Å—Ç–∞—Ç—å, –∑–∞–≤–∏—Å–∞—Ç—å, —Ä–∞–±–æ—Ç–∞, –∞–Ω—Ç–∏–≤–∏—Ä—É—Å, –¥–∞–ª—ë–∫–∏–π, ...  \n",
       "4                  [–æ—á–µ–Ω—å, —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞—Ç—å, –±—ã—Å—Ç—Ä–æ]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Prepared_Content'] = df['Content'].apply(tokenize_and_preprocess)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tokens = []\n",
    "for i in range(len(df_train)):\n",
    "    corpus_tokens += df_train[\"Prepared_Content\"].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "max_words = 5000\n",
    "max_len = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "dist = FreqDist(corpus_tokens)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',\n",
       " '–≤—Å—ë',\n",
       " '–æ—á–µ–Ω—å',\n",
       " '—É–¥–æ–±–Ω–æ',\n",
       " '—Ä–∞–±–æ—Ç–∞—Ç—å',\n",
       " '—É–¥–æ–±–Ω—ã–π',\n",
       " '–æ—Ç–ª–∏—á–Ω–æ',\n",
       " '—Å–ø–∞—Å–∏–±–æ',\n",
       " '—Ö–æ—Ä–æ—à–∏–π',\n",
       " '–Ω—Ä–∞–≤–∏—Ç—å—Å—è']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_filtered_top[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sequence(tokens, maxlen):\n",
    "    result = []\n",
    "    for word in tokens:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "    padding = [0] * (maxlen-len(result))\n",
    "    return padding + result[-maxlen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray([text_to_sequence(text, max_len) for text in df_train[\"Prepared_Content\"]], dtype=np.int32)\n",
    "X_val = np.asarray([text_to_sequence(text, max_len) for text in df_val[\"Prepared_Content\"]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(df_train['Rating'])\n",
    "y_val = label_encoder.fit_transform(df_val['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 512\n",
    "print_batch_n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-28 23:22:49.287347: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-08-28 23:22:49.291369: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(input_dim=max_words, output_dim=128, input_length=max_len),\n",
    "    keras.layers.Conv1D(128, 10),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.GlobalMaxPool1D(),\n",
    "    keras.layers.Dense(25),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(num_classes),\n",
    "    keras.layers.Activation('softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-28 23:25:58.711263: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-08-28 23:26:00.920649: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 7s 114ms/step - loss: 1.0529 - accuracy: 0.6945 - val_loss: 0.8683 - val_accuracy: 0.7082\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-28 23:26:05.479907: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 3s 103ms/step - loss: 0.7515 - accuracy: 0.7538 - val_loss: 0.6782 - val_accuracy: 0.7652\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 0.6245 - accuracy: 0.7805 - val_loss: 0.6384 - val_accuracy: 0.7766\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 3s 101ms/step - loss: 0.5703 - accuracy: 0.7995 - val_loss: 0.6375 - val_accuracy: 0.7793\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 0.5226 - accuracy: 0.8175 - val_loss: 0.6211 - val_accuracy: 0.7839\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 3s 99ms/step - loss: 0.4766 - accuracy: 0.8370 - val_loss: 0.6287 - val_accuracy: 0.7839\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 3s 100ms/step - loss: 0.4314 - accuracy: 0.8568 - val_loss: 0.6456 - val_accuracy: 0.7845\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 3s 98ms/step - loss: 0.3838 - accuracy: 0.8787 - val_loss: 0.6752 - val_accuracy: 0.7729\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 3s 100ms/step - loss: 0.3391 - accuracy: 0.8967 - val_loss: 0.7086 - val_accuracy: 0.7717\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 0.2997 - accuracy: 0.9129 - val_loss: 0.7549 - val_accuracy: 0.7679\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 4s 121ms/step - loss: 0.2678 - accuracy: 0.9235 - val_loss: 0.7957 - val_accuracy: 0.7632\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 4s 125ms/step - loss: 0.2399 - accuracy: 0.9329 - val_loss: 0.8460 - val_accuracy: 0.7595\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 0.2190 - accuracy: 0.9392 - val_loss: 0.8850 - val_accuracy: 0.7590\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 3s 100ms/step - loss: 0.2033 - accuracy: 0.9444 - val_loss: 0.9315 - val_accuracy: 0.7539\n",
      "Epoch 15/20\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 0.1936 - accuracy: 0.9455 - val_loss: 0.9926 - val_accuracy: 0.7562\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 3s 101ms/step - loss: 0.1791 - accuracy: 0.9494 - val_loss: 1.0279 - val_accuracy: 0.7533\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 3s 100ms/step - loss: 0.1706 - accuracy: 0.9515 - val_loss: 1.0624 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 4s 125ms/step - loss: 0.1636 - accuracy: 0.9530 - val_loss: 1.1200 - val_accuracy: 0.7518\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 3s 108ms/step - loss: 0.1572 - accuracy: 0.9548 - val_loss: 1.1497 - val_accuracy: 0.7458\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 3s 102ms/step - loss: 0.1522 - accuracy: 0.9557 - val_loss: 1.1801 - val_accuracy: 0.7433\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ì–æ—Ç–æ–≤—ã–µ –≤–µ—Å–∞\n",
    "\n",
    "https://keras.io/examples/nlp/pretrained_word_embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 154617 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('180/model.txt') as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        word = word.split('_')[0]\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 3304 words (1695 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(vocabulary) + 2\n",
    "embedding_dim = 300\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in vocabulary.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pt = keras.models.Sequential([\n",
    "    keras.layers.Embedding(\n",
    "        input_length=max_len,\n",
    "        input_dim=max_words + 1,\n",
    "        output_dim=embedding_dim,\n",
    "        embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "        trainable=False,\n",
    "    ),\n",
    "    keras.layers.Conv1D(128, 10),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.GlobalMaxPool1D(),\n",
    "    keras.layers.Dense(25),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(num_classes),\n",
    "    keras.layers.Activation('softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pt.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 13:10:00.933225: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - ETA: 0s - loss: 0.9744 - accuracy: 0.7157"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 13:10:04.007957: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 4s 65ms/step - loss: 0.9744 - accuracy: 0.7157 - val_loss: 0.8129 - val_accuracy: 0.7344\n",
      "Epoch 2/20\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.6827 - accuracy: 0.7822 - val_loss: 0.7532 - val_accuracy: 0.7454\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.5730 - accuracy: 0.8192 - val_loss: 0.7411 - val_accuracy: 0.7508\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.4862 - accuracy: 0.8537 - val_loss: 0.7527 - val_accuracy: 0.7535\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.4223 - accuracy: 0.8746 - val_loss: 0.7648 - val_accuracy: 0.7483\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.3694 - accuracy: 0.8925 - val_loss: 0.7954 - val_accuracy: 0.7431\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.3307 - accuracy: 0.9041 - val_loss: 0.8355 - val_accuracy: 0.7491\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.2990 - accuracy: 0.9142 - val_loss: 0.8645 - val_accuracy: 0.7483\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.2731 - accuracy: 0.9202 - val_loss: 0.8882 - val_accuracy: 0.7495\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.2564 - accuracy: 0.9253 - val_loss: 0.9278 - val_accuracy: 0.7477\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.2433 - accuracy: 0.9291 - val_loss: 1.0005 - val_accuracy: 0.7466\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.2348 - accuracy: 0.9313 - val_loss: 1.0108 - val_accuracy: 0.7431\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.2302 - accuracy: 0.9335 - val_loss: 1.0197 - val_accuracy: 0.7429\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2205 - accuracy: 0.9357 - val_loss: 1.0952 - val_accuracy: 0.7450\n",
      "Epoch 15/20\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.2116 - accuracy: 0.9380 - val_loss: 1.1056 - val_accuracy: 0.7322\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2088 - accuracy: 0.9398 - val_loss: 1.1169 - val_accuracy: 0.7348\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.2006 - accuracy: 0.9421 - val_loss: 1.1430 - val_accuracy: 0.7382\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.1934 - accuracy: 0.9437 - val_loss: 1.1702 - val_accuracy: 0.7425\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.1880 - accuracy: 0.9450 - val_loss: 1.2474 - val_accuracy: 0.7394\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.1838 - accuracy: 0.9462 - val_loss: 1.2263 - val_accuracy: 0.7382\n"
     ]
    }
   ],
   "source": [
    "history = model_pt.fit(X_train, y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__–í—ã–≤–æ–¥:__ –æ–±—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å –∏ —Å –ø—Ä–µ–æ–±—É—á–µ–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏ —ç–º–±–µ–¥–∏–Ω–≥–∞ –æ–¥–∏–Ω–∞–∫–æ–≤–æ —Ö–æ—Ä–æ—à–æ –ø—Ä–æ—è–≤–∏–ª–∏ —Å–µ–±—è –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ, –æ–±—ã—á–Ω–∞—è –¥–∞–∂–µ –Ω–µ–º–Ω–æ–≥–æ –ª—É—á—à–µ."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3af7e179898fb99d78969cca94508015726394a06defd0be323cbf435423c41d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('nn': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
