{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUotKHRULVPD"
   },
   "source": [
    "# Инструменты для работы с языком "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ba5Z02VLVPK"
   },
   "source": [
    "## Задача: классификация твитов по тональности\n",
    "\n",
    "У нас есть датасет из твитов, про каждый указано, как он эмоционально окрашен: положительно или отрицательно. Задача: предсказывать эмоциональную окраску.\n",
    "\n",
    "Скачиваем куски датасета ([источник](http://study.mokoron.com/)): [положительные](https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0), [отрицательные](https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zHB70n5LVPN",
    "outputId": "76e9cc41-c912-464c-a06e-e02879e69c08",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-08-08 15:07:05--  https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.71.18\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.71.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/fnpq3z4bcnoktiv/positive.csv [following]\n",
      "--2022-08-08 15:07:06--  https://www.dropbox.com/s/raw/fnpq3z4bcnoktiv/positive.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ucb7d8eb2647f9c84c659f5fb1bf.dl.dropboxusercontent.com/cd/0/inline/Bqk0yiOfuOTNF67chfOCsbL_6nCIQc06zq_X0_00V_kp7kVnxj8P12T3qBTMma7b0fl0ARUjmN3IOJCsu6MnbbZ1pgIFqhKiFjZtN2gyNNJ0pmNha6l96l_N1ghIznEM4P7J_YbSIO1QPVHvG-ofccm8WEAEzO7EBRgOwdlbMgprZw/file# [following]\n",
      "--2022-08-08 15:07:06--  https://ucb7d8eb2647f9c84c659f5fb1bf.dl.dropboxusercontent.com/cd/0/inline/Bqk0yiOfuOTNF67chfOCsbL_6nCIQc06zq_X0_00V_kp7kVnxj8P12T3qBTMma7b0fl0ARUjmN3IOJCsu6MnbbZ1pgIFqhKiFjZtN2gyNNJ0pmNha6l96l_N1ghIznEM4P7J_YbSIO1QPVHvG-ofccm8WEAEzO7EBRgOwdlbMgprZw/file\n",
      "Resolving ucb7d8eb2647f9c84c659f5fb1bf.dl.dropboxusercontent.com (ucb7d8eb2647f9c84c659f5fb1bf.dl.dropboxusercontent.com)... 162.125.71.15\n",
      "Connecting to ucb7d8eb2647f9c84c659f5fb1bf.dl.dropboxusercontent.com (ucb7d8eb2647f9c84c659f5fb1bf.dl.dropboxusercontent.com)|162.125.71.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 26233379 (25M) [text/plain]\n",
      "Saving to: ‘positive.csv’\n",
      "\n",
      "positive.csv        100%[===================>]  25,02M  2,23MB/s    in 11s     \n",
      "\n",
      "2022-08-08 15:07:18 (2,32 MB/s) - ‘positive.csv’ saved [26233379/26233379]\n",
      "\n",
      "--2022-08-08 15:07:18--  https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.71.18\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.71.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/r6u59ljhhjdg6j0/negative.csv [following]\n",
      "--2022-08-08 15:07:19--  https://www.dropbox.com/s/raw/r6u59ljhhjdg6j0/negative.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc72006e280823df7ed31db79185.dl.dropboxusercontent.com/cd/0/inline/BqnmDGq3gR5knSRhftWM_LdrzMDk4chMIojubmoFiKuurSIsiEPmyPZLzhzWQtBDAbHE4otUQwwFoKm7K1XBXJvXAqroQp26PY7xEhlBy9O2AfYUqviGv19GyivdIaQRNsPkLuvF5oJFKCNJk2pWJEuSCq0O2xspUq8qRPuKGXZdmQ/file# [following]\n",
      "--2022-08-08 15:07:19--  https://uc72006e280823df7ed31db79185.dl.dropboxusercontent.com/cd/0/inline/BqnmDGq3gR5knSRhftWM_LdrzMDk4chMIojubmoFiKuurSIsiEPmyPZLzhzWQtBDAbHE4otUQwwFoKm7K1XBXJvXAqroQp26PY7xEhlBy9O2AfYUqviGv19GyivdIaQRNsPkLuvF5oJFKCNJk2pWJEuSCq0O2xspUq8qRPuKGXZdmQ/file\n",
      "Resolving uc72006e280823df7ed31db79185.dl.dropboxusercontent.com (uc72006e280823df7ed31db79185.dl.dropboxusercontent.com)... 162.125.71.15\n",
      "Connecting to uc72006e280823df7ed31db79185.dl.dropboxusercontent.com (uc72006e280823df7ed31db79185.dl.dropboxusercontent.com)|162.125.71.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 24450101 (23M) [text/plain]\n",
      "Saving to: ‘negative.csv’\n",
      "\n",
      "negative.csv        100%[===================>]  23,32M  2,24MB/s    in 11s     \n",
      "\n",
      "2022-08-08 15:07:30 (2,18 MB/s) - ‘negative.csv’ saved [24450101/24450101]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# если у вас линукс / мак / collab или ещё какая-то среда, в которой работает wget, можно так:\n",
    "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
    "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "J5YiZNCPLVPe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DFLtXAZ-LVPq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fm/c7ljnhr1431byzjw21b2hzy00000gn/T/ipykernel_79414/3125191635.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = positive.append(negative)\n"
     ]
    }
   ],
   "source": [
    "# считываем данные и заполняем общий датасет\n",
    "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "positive['label'] = ['positive'] * len(positive)\n",
    "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "negative['label'] = ['negative'] * len(negative)\n",
    "df = positive.append(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "j1AEISlBLVP0",
    "outputId": "443eadf2-9df4-4507-f2a5-a64f7968182f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111918</th>\n",
       "      <td>Но не каждый хочет что то исправлять:( http://...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111919</th>\n",
       "      <td>скучаю так :-( только @taaannyaaa вправляет мо...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111920</th>\n",
       "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111921</th>\n",
       "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111922</th>\n",
       "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text     label\n",
       "111918  Но не каждый хочет что то исправлять:( http://...  negative\n",
       "111919  скучаю так :-( только @taaannyaaa вправляет мо...  negative\n",
       "111920          Вот и в школу, в говно это идти уже надо(  negative\n",
       "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...  negative\n",
       "111922  Такси везет меня на работу. Раздумываю приплат...  negative"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ZWta7oDgLVP8"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAapBC7VLVQC"
   },
   "source": [
    "## Baseline: классификация необработанных n-грамм\n",
    "\n",
    "### Векторизаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "M-AvVt8XLVQD"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # можно заменить на любимый классификатор\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSuoVoxcLVQI"
   },
   "source": [
    "Что такое n-граммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zeNA7732LVQJ"
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NeApDOmrLVQN",
    "outputId": "d8c763fe-2658-47ac-fcee-5b7bbe49f0d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если',), ('б',), ('мне',), ('платили',), ('каждый',), ('раз',)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'Если б мне платили каждый раз'.split()\n",
    "list(ngrams(sent, 1)) # униграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPAS0fS-LVQQ",
    "outputId": "aa3ae031-c661-4639-b7ab-f93ba1b6cee5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б'),\n",
       " ('б', 'мне'),\n",
       " ('мне', 'платили'),\n",
       " ('платили', 'каждый'),\n",
       " ('каждый', 'раз')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 2)) # биграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d77jmVPhLVQU",
    "outputId": "c8de801b-8efc-437e-8673-4e9e31665ea5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне'),\n",
       " ('б', 'мне', 'платили'),\n",
       " ('мне', 'платили', 'каждый'),\n",
       " ('платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 3)) # триграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5xXTBrGELVQX",
    "outputId": "f5b423d9-db6b-4efa-8bfa-a446a55ee018"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне', 'платили', 'каждый'),\n",
       " ('б', 'мне', 'платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 5)) # ... пентаграммы?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHGJBEm-LVQb"
   },
   "source": [
    "Самый простой способ извлечь фичи из текстовых данных -- векторизаторы: `CountVectorizer` и `TfidfVectorizer`\n",
    "\n",
    "Объект `CountVectorizer` делает простую вещь:\n",
    "* строит для каждого документа (каждой пришедшей ему строки) вектор размерности `n`, где `n` -- количество слов или n-грам во всём корпусе\n",
    "* заполняет каждый i-тый элемент количеством вхождений слова в данный документ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "eMqZFBTgLVQb"
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train) # bow -- bag of words (мешок слов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZkpqVtILVQe"
   },
   "source": [
    "ngram_range отвечает за то, какие n-граммы мы используем в качестве фичей:<br/>\n",
    "ngram_range=(1, 1) -- униграммы<br/>\n",
    "ngram_range=(3, 3) -- триграммы<br/>\n",
    "ngram_range=(1, 3) -- униграммы, биграммы и триграммы.\n",
    "\n",
    "В vec.vocabulary_ лежит словарь: мэппинг слов к их индексам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWRtOSzKLVQf",
    "outputId": "668857b0-def2-4547-8fd5-014fe3858bec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rt', 74409),\n",
       " ('gy_hab', 35847),\n",
       " ('вот', 114726),\n",
       " ('вырастут', 117490),\n",
       " ('тебя', 220693),\n",
       " ('сиськи', 209540),\n",
       " ('приеду', 193576),\n",
       " ('тебе', 220686),\n",
       " ('трахну', 223232),\n",
       " ('того', 222087)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vec.vocabulary_.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hkmX3iBbLVQi",
    "outputId": "5bbb432e-1c45-422a-edc2-60841ef0ee33"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=42)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42, max_iter=10000)\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bJ8q5_59LVQm",
    "outputId": "d88c6de2-640a-4cc9-ae95-29fe12c80131"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.76      0.77     28326\n",
      "    positive       0.76      0.77      0.77     28383\n",
      "\n",
      "    accuracy                           0.77     56709\n",
      "   macro avg       0.77      0.77      0.77     56709\n",
      "weighted avg       0.77      0.77      0.77     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAhgaYgqLVQp"
   },
   "source": [
    "Попробуем сделать то же самое для триграмм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GPWXlh6ALVQq",
    "outputId": "094a7189-bc36-42df-81ee-f599a206ca0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      0.72      0.57     18262\n",
      "    positive       0.82      0.61      0.70     38447\n",
      "\n",
      "    accuracy                           0.64     56709\n",
      "   macro avg       0.64      0.66      0.63     56709\n",
      "weighted avg       0.71      0.64      0.66     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(3, 3))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42, max_iter=10000)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnfyJkzTLVQu"
   },
   "source": [
    "(как вы думаете, почему в результатах теперь такой разброс по сравнению с униграммами?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJABxhalLVQu"
   },
   "source": [
    "## TF-IDF векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LJES2s-LVQv"
   },
   "source": [
    "`TfidfVectorizer` делает то же, что и `CountVectorizer`, но в качестве значений – tf-idf каждого слова.\n",
    "\n",
    "Как считается tf-idf:\n",
    "\n",
    "TF (term frequency) – относительная частотность слова в документе:\n",
    "$$ TF(t,d) = \\frac{n_t}{\\sum_k n_k} $$\n",
    "\n",
    "`t` -- слово (term), `d` -- документ, $n_t$ -- количество вхождений слова, $n_k$ -- количество вхождений остальных слов\n",
    "\n",
    "IDF (inverse document frequency) – обратная частота документов, в которых есть это слово:\n",
    "$$ IDF(t, D) = \\mbox{log} \\frac{|D|}{|{d : t \\in d}|} $$\n",
    "\n",
    "`t` -- слово (term), `D` -- коллекция документов\n",
    "\n",
    "Перемножаем их:\n",
    "$$TFIDF_(t,d,D) = TF(t,d) \\times IDF(i, D)$$\n",
    "\n",
    "Сакральный смысл – если слово часто встречается в одном документе, но в целом по корпусу встречается в небольшом \n",
    "количестве документов, у него высокий TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "FmEcRD28LVQ0"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AWLhMl9xLVQ3",
    "outputId": "054e5662-1c41-42f6-92e4-ce0194317ce8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.77      0.75     26831\n",
      "    positive       0.79      0.75      0.77     29878\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTODTRnKLVQ6"
   },
   "source": [
    "В этот раз получилось хуже :( Вернёмся к `CountVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8v9Scpn9Y0M"
   },
   "source": [
    "## PMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVRqLcSY0etj"
   },
   "source": [
    "Можно оценить взаимосвязь слов в корпусе и понять, какие биграммы наиболее часто встречаются в тексте. Для этого можно использовать метрику PMI (Pointwise Mutual Information) - поточечная взаимная информация. Метрика PMI для двух слов вычисляется по формуле:\n",
    "\n",
    "$$pmi(x; y) = log \\frac{p(x,y)}{p(x)p(y)} $$\n",
    "\n",
    "Здесь p(y|x) - вероятность встретить слово $y$ после $x$, $p(y)$ - вероятность встретить слово $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXgDwf6W6Kk5"
   },
   "source": [
    "Оценим важность биграмм в нашем обучающем корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LKmiOEaW53F9",
    "outputId": "96a85968-e0cb-4b17-cd62-bc3de5e3e9b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package genesis to /Users/blaze/nltk_data...\n",
      "[nltk_data]   Package genesis is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/blaze/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "[('+1239', '728'), ('+375447167151', 'звоги'), ('+Никита', '=полностью'), ('+СОННО', '+НЕ'), ('+погода', 'крутая='), (',4', 'запирайте'), (',Дела', 'рез'), ('-10,11', 'болсо'), ('-165', '-СИНИЙ'), ('-53', 'dBm'), ('-800', 'нахууй'), ('-АХАХАХАХ', 'ЮБКУ'), ('-АХАХАХАХХАХАХАХАХАХХА', '-АХАХАХХАХАХАХАХАХ'), ('-Айгуль', 'Маратовна'), ('-Алина', '-Синие'), ('-Аха', 'спетросянил'), ('-ВАХАХАХА', 'СТИПЕНДИЯ'), ('-ВСЕМ', 'СПОКОЙНЫХ'), ('-Весело', 'кншн:3'), ('-Восьмигрудый', 'трипи'), ('-Время', 'эмокора'), ('-ГНИДОТА', '-Над'), ('-Д-Д-Д-Д-Д-Д-ДРОП', 'ЗЭ'), ('-ДЕТЕЙ', 'НАКРЫЛО'), ('-Домашка', '-кл.час'), ('-ЖАРЕНЫЙ', 'КАРТОФЕЛЬ'), ('-ЖРАТЬ', 'БАРАНКИ'), ('-Защитано', '-ес'), ('-Керем', 'севгили'), ('-Лера', 'Синим'), ('-Мамаааа', 'поправь'), ('-НА', 'РЕАЛЬНЫХ'), ('-НАЧИНАЕТ', 'БЕСИТЬ'), ('-ОЗВУЧИВАТЕЛЬ', 'МУЛЬТИКОВ'), ('-Песня', 'грусная='), ('-Плохое', 'пищеварение'), ('-Поэзия', 'заключает'), ('-Рыбу', 'соленую'), ('-СИНИЙ', '-БЕЛЫЕ'), ('-Серые', '-НЕМЕЦКИЕ'), ('-Танцы', '-Хорошие'), ('-Ти', 'кантужена'), ('-Тиць', 'дурне'), ('-Трахався', '-Іди'), ('-Филл', '-познакомились'), ('-ШАПКА', '-ФОН'), ('-Школа', '-Плохие'), ('-Я.банан', '-ахх'), ('-анал', '-абстиненция'), ('-анатолий', 'николаевич'), ('-бляя', 'хммммммм'), ('-водичку', 'лью'), ('-г', 'үзээ'), ('-говорит', 'одноногий'), ('-дерьмо', 'редкосное'), ('-дирекшионер', '-one'), ('-иногда', '.Ностальгирую'), ('-киллджой', '-шатенка'), ('-классный', 'фильм.правда'), ('-кучи', 'мутики'), ('-ладно', '-АХАХАХАХХАХАХАХАХАХХА'), ('-ложусь', 'спать-темно'), ('-любому', 'умрёшь'), ('-место', '-кровать'), ('-напиши', '-нит'), ('-наш', 'класс^^'), ('-новый', 'молодежный'), ('-патлатые', '-лысый'), ('-пиши', 'Ненси'), ('-попробуй', 'помедитировать'), ('-раз', 'плёткой'), ('-раздевайся', '-дак'), ('-распускаю', 'волосы-'), ('-руу', 'орох'), ('-случайные', 'вопросы-'), ('-соскучилась', '-по'), ('-спрашивает', 'жена.-У'), ('-столько', 'бабосов'), ('-такое', 'ВЧ-8='), ('-твиты', '+био'), ('-ти', 'классников'), ('-удивительная', 'штука.Его'), ('-указуказуказуказуа', '-материшся'), ('-хаски', '-розовое'), ('-хор', '-найл'), ('-хуи', 'сосешь'), ('-цвета', 'Магнита'), ('-цитирую', 'гастролога'), ('-цытата', 'Шимы'), ('-черные', '-аниме'), ('-ыг', 'үгүйсгэж'), ('-эртага', 'бозорга'), ('-языком', 'владеешь'), ('.Прозвучало', 'неубедительно.Учитель'), ('.Суудлынхаа', 'даруулгыг'), ('.Хочу', 'миксануть'), ('.всё', 'неполноценность.я'), ('.выражаешься', '.то'), ('.горло', 'плохое.живот'), ('.колеса', 'сдуваются')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import collocations \n",
    "nltk.download('genesis')\n",
    "nltk.download('punkt')\n",
    "\n",
    "print(type(nltk.corpus.genesis.words('english-web.txt')))\n",
    "bigram_measures = collocations.BigramAssocMeasures()\n",
    "# bigram_finder.apply_freq_filter(5)\n",
    "bigram_finder = collocations.BigramCollocationFinder.from_documents([nltk.word_tokenize(x) for x in x_train])\n",
    "bigrams = bigram_finder.nbest(bigram_measures.pmi, 100)\n",
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_h4Cq1PUTTc-"
   },
   "source": [
    "Можно рассмотреть другие метрики оценки важности биграмм, например, метрику правдоподобия (подробнее про вычисление метрики можно посмотреть [здесь (пункт 5.3.4)](http://www.corpus.unam.mx/cursoenah/ManningSchutze_1999_FoundationsofStatisticalNaturalLanguageProcessing.pdf):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lTOJg4KoOo84",
    "outputId": "45d38953-84e0-4a65-fccd-1e96fd83c3f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('(', '('), ('RT', '@'), (')', ')'), ('http', ':'), ('!', '!'), (':', 'D'), ('у', 'меня'), (':', '('), (',', 'а'), (',', 'что'), (',', 'но'), (')', 'http'), ('*', '*'), (':', ')'), ('(', ','), ('у', 'нас'), (':', '-'), (',', '('), ('не', 'могу'), (',', ')'), ('?', '?'), (')', ','), (',', ':'), ('@', '('), (',', ','), (':', ','), ('(', ':'), ('@', ')'), ('&', 'lt'), ('@', ','), ('со', 'мной'), ('@', ':'), ('(', '@'), ('новый', 'год'), (':', ':'), (';', ')'), (':', '*'), ('gt', ';'), ('не', 'знаю'), (')', ':'), (',', '@'), ('а', 'я'), ('@', '@'), ('потому', 'что'), ('lt', ';'), (',', 'когда'), ('сих', 'пор'), ('У', 'меня'), ('&', 'gt'), ('у', 'тебя'), (';', '('), ('с', 'тобой'), ('все', 'равно'), ('в', 'школу'), (',', 'как'), (',', 'я'), (')', '@'), ('&', 'amp'), ('(', 'http'), ('Доброе', 'утро'), ('ничего', 'не'), ('-', ')'), ('я', 'не'), ('Как', 'же'), (':', 'DD'), ('--', '--'), ('не', '('), ('самом', 'деле'), ('не', ')'), (',', 'чтобы'), ('как', 'же'), ('до', 'сих'), ('amp', ';'), ('что', 'я'), (',', '!'), ('(', '!'), ('D', 'http'), ('об', 'этом'), ('не', ':'), ('никто', 'не'), ('=', ')'), ('и', '('), ('.', 'А'), ('!', ','), ('с', 'кем'), (':', '!'), ('?', '—'), ('а', 'потом'), (':', '|'), ('никогда', 'не'), ('и', ')'), (',', '.'), ('Новый', 'Год'), ('.', ','), ('@', 'не'), ('не', '@'), ('в', 'этом'), ('#', 'євромайдан'), ('.', 'Но'), ('“', '@')]\n"
     ]
    }
   ],
   "source": [
    "bigrams = bigram_finder.nbest(bigram_measures.likelihood_ratio, 100)\n",
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfjCYZa8TeX_"
   },
   "source": [
    "Как можно заметить, немаловажную роль в текстах занимает пунктуация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AJk1B39LVRP"
   },
   "source": [
    "## Стоп-слова и пунктуация\n",
    "\n",
    "*Стоп-слова* -- это слова, которые часто встречаются практически в любом тексте и ничего интересного не говорят о конретном документе, то есть играют роль шума. Поэтому их принято убирать. По той же причине убирают и пунктуацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fpWhsTuRLVRP",
    "outputId": "1cd18efe-a3cd-4f56-ec4c-bec8b6ee442e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/blaze/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# у вас здесь, вероятно, выскочит ошибка и надо будет загрузить стоп слова (в тексте ошибки написано, как)\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "print(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "OdRF7rlyLVRS",
    "outputId": "dd4ce4f0-13d0-4b21-a3a1-b9ecb281894f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "OfXiH98XLVRV"
   },
   "outputs": [],
   "source": [
    "noise = stopwords.words('russian') + list(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtiIhHDMLVRY"
   },
   "source": [
    "В векторизаторах за стоп-слова, логичным образом, отвечает аргумент `stop_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZnbarm_LVRY",
    "outputId": "88f40278-165a-46ad-a75e-2e5d8e7e3a4d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/nn/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/nn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.77      0.78     29289\n",
      "    positive       0.76      0.79      0.78     27420\n",
      "\n",
      "    accuracy                           0.78     56709\n",
      "   macro avg       0.78      0.78      0.78     56709\n",
      "weighted avg       0.78      0.78      0.78     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=noise)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wr934O7yLVRb"
   },
   "source": [
    "Получилось чууть лучше. Что ещё можно сделать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7O_oD1fLVRc"
   },
   "source": [
    "## Лемматизация\n",
    "\n",
    "Лемматизация – это сведение разных форм одного слова к начальной форме – *лемме*. Почему это хорошо?\n",
    "* Во-первых, мы хотим рассматривать как отдельную фичу каждое *слово*, а не каждую его отдельную форму.\n",
    "* Во-вторых, некоторые стоп-слова стоят только в начальной форме, и без лематизации выкидываем мы только её.\n",
    "\n",
    "Для русского есть два хороших лемматизатора: mystem и pymorphy:\n",
    "\n",
    "### [Mystem](https://tech.yandex.ru/mystem/)\n",
    "Как с ним работать:\n",
    "* можно скачать mystem и запускать [из терминала с разными параметрами](https://tech.yandex.ru/mystem/doc/)\n",
    "* [pymystem3](https://pythonhosted.org/pymystem3/pymystem3.html) - обертка для питона, работает медленнее, но это удобно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96HdoB7zLVRc",
    "outputId": "987397bc-55cb-4830-c361-5568f1f2e015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-09-09 13:19:45--  http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
      "Resolving download.cdn.yandex.net (download.cdn.yandex.net)... 5.45.205.244, 5.45.205.243, 5.45.205.245, ...\n",
      "Connecting to download.cdn.yandex.net (download.cdn.yandex.net)|5.45.205.244|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cachev2-spb03.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz?lid=122 [following]\n",
      "--2021-09-09 13:19:46--  https://cachev2-spb03.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz?lid=122\n",
      "Resolving cachev2-spb03.cdn.yandex.net (cachev2-spb03.cdn.yandex.net)... 37.140.137.3, 2a02:6b8:0:2221::303\n",
      "Connecting to cachev2-spb03.cdn.yandex.net (cachev2-spb03.cdn.yandex.net)|37.140.137.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16457938 (16M) [application/octet-stream]\n",
      "Saving to: ‘mystem-3.0-linux3.1-64bit.tar.gz.1’\n",
      "\n",
      "mystem-3.0-linux3.1 100%[===================>]  15.70M  9.80MB/s    in 1.6s    \n",
      "\n",
      "2021-09-09 13:19:49 (9.80 MB/s) - ‘mystem-3.0-linux3.1-64bit.tar.gz.1’ saved [16457938/16457938]\n",
      "\n",
      "mystem\n"
     ]
    }
   ],
   "source": [
    "!wget http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
    "!tar -xvf mystem-3.0-linux3.1-64bit.tar.gz\n",
    "!cp mystem /bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzQwGwAaZWV5"
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "mystem_analyzer = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_w-_fkNtLVRf"
   },
   "source": [
    "Мы инициализировали Mystem c дефолтными параметрами. А вообще параметры есть такие:\n",
    "* mystem_bin - путь к `mystem`, если их несколько\n",
    "* grammar_info - нужна ли грамматическая информация или только леммы (по дефолту нужна)\n",
    "* disambiguation - нужно ли снятие омонимии - дизамбигуация (по дефолту нужна)\n",
    "* entire_input - нужно ли сохранять в выводе все (пробелы всякие, например), или можно выкинуть (по дефолту оставляется все)\n",
    "\n",
    "Методы Mystem принимают строку, токенизатор вшит внутри. Можно, конечно, и пословно анализировать, но тогда он не сможет учитывать контекст.\n",
    "\n",
    "Можно просто лемматизировать текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjHHLQv9txDq",
    "outputId": "35bcb3cc-7853-48bf-d38d-04157f45221d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['но', ' ', 'не', ' ', 'каждый', ' ', 'хотеть', ' ', 'что-то', ' ', 'исправлять', ':(\\n']\n"
     ]
    }
   ],
   "source": [
    "print(mystem_analyzer.lemmatize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RI1eftjkLVRi"
   },
   "source": [
    "А можно получить грамматическую информацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j4MLqlZnxNEj",
    "outputId": "ffb676bb-932e-4579-817a-c15616431521"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'gr': 'CONJ=', 'lex': 'но', 'wt': 0.9998906255}],\n",
       "  'text': 'Но'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'PART=', 'lex': 'не', 'wt': 1}], 'text': 'не'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'APRO=(вин,ед,муж,неод|им,ед,муж)',\n",
       "    'lex': 'каждый',\n",
       "    'wt': 0.9985975623}],\n",
       "  'text': 'каждый'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'V,несов,пе=непрош,ед,изъяв,3-л',\n",
       "    'lex': 'хотеть',\n",
       "    'wt': 1}],\n",
       "  'text': 'хочет'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'SPRO,ед,сред,неод=(вин|им)', 'lex': 'что-то', 'wt': 1}],\n",
       "  'text': 'что-то'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'V,пе=инф,несов', 'lex': 'исправлять', 'wt': 1}],\n",
       "  'text': 'исправлять'},\n",
       " {'text': ':(\\n'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_analyzer.analyze(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADcGtz4JLVRl"
   },
   "source": [
    "Давайте терепь используем лемматизатор майстема в качестве токенизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x48Q56tiLVRn"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def my_preproc(text):\n",
    "    text = re.sub('[{}]'.format(punctuation), '', text)\n",
    "    text = mystem_analyzer.lemmatize(text)\n",
    "    return [word for word in text if word not in stopwords.words('russian') + [' ', '\\n']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEwOQTJPLVRq",
    "outputId": "b1047a05-9fa7-4994-c947-578cfc4d9825"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.74      0.76     29425\n",
      "    positive       0.73      0.77      0.75     27284\n",
      "\n",
      "    accuracy                           0.75     56709\n",
      "   macro avg       0.75      0.75      0.75     56709\n",
      "weighted avg       0.75      0.75      0.75     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=my_preproc)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJlvqWuALVRs"
   },
   "source": [
    "### [Pymorphy](http://pymorphy2.readthedocs.io/en/latest/)\n",
    "Это модуль на питоне, довольно быстрый и с кучей функций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tHDkurN1zf7g",
    "outputId": "c9934446-bf72-4603-8a51-9f6ebf406e44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2\n",
      "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "\u001b[?25l\r\n",
      "\u001b[K     |██████                          | 10 kB 23.5 MB/s eta 0:00:01\r\n",
      "\u001b[K     |███████████▉                    | 20 kB 25.8 MB/s eta 0:00:01\r\n",
      "\u001b[K     |█████████████████▊              | 30 kB 12.2 MB/s eta 0:00:01\r\n",
      "\u001b[K     |███████████████████████▋        | 40 kB 9.6 MB/s eta 0:00:01\r\n",
      "\u001b[K     |█████████████████████████████▌  | 51 kB 4.9 MB/s eta 0:00:01\r\n",
      "\u001b[K     |████████████████████████████████| 55 kB 1.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
      "Collecting dawg-python>=0.7.1\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.2 MB 10.7 MB/s \n",
      "\u001b[?25hInstalling collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7SlwsLU7LVRt"
   },
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "pymorphy2_analyzer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qaz0x7frLVRw"
   },
   "source": [
    "pymorphy2 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, т.к. не понимает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdf6XoEbLVRw",
    "outputId": "a1984e06-dbeb-4377-896d-b7014b6b84c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='платили', tag=OpencorporaTag('VERB,impf,tran plur,past,indc'), normal_form='платить', score=1.0, methods_stack=((DictionaryAnalyzer(), 'платили', 2472, 10),))]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana = pymorphy2_analyzer.parse(sent[3])\n",
    "ana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "0KuHQGPgLVRz",
    "outputId": "3cdbe79d-ec3f-4a07-ff3a-52e8810face1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'платить'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gg0EASPcLVR8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFTkF8xUARlS"
   },
   "source": [
    "### [Natasha](https://github.com/natasha/)\n",
    "\n",
    "В библиотеке natasha реализовано множество полезных библиотек для русского языка: разбиение на токены и предложения, русскоязычные word embeddings, морфологический, синтаксический анализ, лемматизация, извлечение именованных сущностей и т.д. Модуль библиотеки Razdel, основанный на правилах, предназначен для разбиения текста на токены и предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CVeDxeIA6rg",
    "outputId": "ff583009-ae7a-4b68-b6a7-ca1ba48c0732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting razdel\n",
      "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: razdel\n",
      "Successfully installed razdel-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MOTkw9MpAnNN",
    "outputId": "51fc6e54-3b82-4c1c-91c2-5b6a60f6304f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Substring(0, 13, 'Кружка-термос'),\n",
       " Substring(14, 16, 'на'),\n",
       " Substring(17, 20, '0.5'),\n",
       " Substring(20, 21, 'л'),\n",
       " Substring(22, 23, '('),\n",
       " Substring(23, 28, '50/64'),\n",
       " Substring(29, 32, 'см³'),\n",
       " Substring(32, 33, ','),\n",
       " Substring(34, 37, '516'),\n",
       " Substring(37, 38, ';'),\n",
       " Substring(38, 41, '...'),\n",
       " Substring(41, 42, ')')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from razdel import tokenize\n",
    "\n",
    "tokens = list(tokenize('Кружка-термос на 0.5л (50/64 см³, 516;...)'))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ftx-WzUbBCpO",
    "outputId": "40c67fa4-fab6-4c1b-f651-06951a38798e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Кружка-термос',\n",
       " 'на',\n",
       " '0.5',\n",
       " 'л',\n",
       " '(',\n",
       " '50/64',\n",
       " 'см³',\n",
       " ',',\n",
       " '516',\n",
       " ';',\n",
       " '...',\n",
       " ')']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_.text for _ in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uyhsQp4MGbW8",
    "outputId": "55f84576-aaad-4a68-c5d9-38dc0ea2f721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting natasha\n",
      "  Downloading natasha-1.4.0-py3-none-any.whl (34.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 34.4 MB 30 kB/s \n",
      "\u001b[?25hCollecting ipymarkup>=0.8.0\n",
      "  Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
      "Collecting navec>=0.9.0\n",
      "  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.9.1)\n",
      "Collecting yargy>=0.14.0\n",
      "  Downloading yargy-0.15.0-py3-none-any.whl (41 kB)\n",
      "\u001b[K     |████████████████████████████████| 41 kB 102 kB/s \n",
      "\u001b[?25hCollecting slovnet>=0.3.0\n",
      "  Downloading slovnet-0.5.0-py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 4.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: razdel>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.5.0)\n",
      "Collecting intervaltree>=3\n",
      "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from navec>=0.9.0->natasha) (1.19.5)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
      "Building wheels for collected packages: intervaltree\n",
      "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26119 sha256=c21bb14c19f5774a60e5bb5d903ac3f80d37a2760af69683789029fcfa71fc54\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/85/bd/1001cbb46dcfb71c2001cd7401c6fb250392f22a81ce3722f7\n",
      "Successfully built intervaltree\n",
      "Installing collected packages: navec, intervaltree, yargy, slovnet, ipymarkup, natasha\n",
      "  Attempting uninstall: intervaltree\n",
      "    Found existing installation: intervaltree 2.1.0\n",
      "    Uninstalling intervaltree-2.1.0:\n",
      "      Successfully uninstalled intervaltree-2.1.0\n",
      "Successfully installed intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.4.0 navec-0.10.0 slovnet-0.5.0 yargy-0.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install natasha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMO3jsqLKSIV"
   },
   "source": [
    "С помощью библиотеки natasha можно также лемматизировать тексты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vJZgfRnvIS2q"
   },
   "outputs": [],
   "source": [
    "from natasha import Doc, MorphVocab, Segmenter, NewsEmbedding, NewsMorphTagger\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "\n",
    "def natasha_lemmatize(text):\n",
    "  doc = Doc(text)\n",
    "  doc.segment(segmenter)\n",
    "  doc.tag_morph(morph_tagger)\n",
    "  for token in doc.tokens:\n",
    "    token.lemmatize(morph_vocab)\n",
    "  return {_.text: _.lemma for _ in doc.tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBtlnYlFBOKv",
    "outputId": "47a9e7d6-7f03-4e93-e57c-84dce5657d97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(': '(',\n",
       " ')': ')',\n",
       " ',': ',',\n",
       " '.': '.',\n",
       " '1': '1',\n",
       " '11': '11',\n",
       " '110-летия': '110-летие',\n",
       " '1909': '1909',\n",
       " '1909-1959': '1909-1959',\n",
       " '2010': '2010',\n",
       " '2019': '2019',\n",
       " 'Twitter': 'twitter',\n",
       " '«': '«',\n",
       " '»': '»',\n",
       " 'Бандера': 'бандера',\n",
       " 'Бандере': 'бандера',\n",
       " 'Бандеры': 'бандера',\n",
       " 'В': 'в',\n",
       " 'Верховной': 'верховный',\n",
       " 'Виктора': 'виктор',\n",
       " 'Героем': 'герой',\n",
       " 'Героя': 'герой',\n",
       " 'Житомирский': 'житомирский',\n",
       " 'Израиля': 'израиль',\n",
       " 'Йоэль': 'йоэль',\n",
       " 'Лион': 'лион',\n",
       " 'Львовский': 'львовский',\n",
       " 'Львовской': 'львовский',\n",
       " 'ОУН': 'оун',\n",
       " 'Организации': 'организация',\n",
       " 'Парламентарии': 'парламентарий',\n",
       " 'Петру': 'петр',\n",
       " 'Порошенко': 'порошенко',\n",
       " 'Посол': 'посол',\n",
       " 'Рады': 'рада',\n",
       " 'России': 'россия',\n",
       " 'Свое': 'свой',\n",
       " 'Степан': 'степан',\n",
       " 'Степана': 'степан',\n",
       " 'Украина': 'украина',\n",
       " 'Украине': 'украина',\n",
       " 'Украины': 'украина',\n",
       " 'Ющенко': 'ющенко',\n",
       " 'Я': 'я',\n",
       " 'а': 'а',\n",
       " 'аналогичное': 'аналогичный',\n",
       " 'антисемитизмом': 'антисемитизм',\n",
       " 'антисемитских': 'антисемитский',\n",
       " 'бороться': 'бороться',\n",
       " 'борьбе': 'борьба',\n",
       " 'был': 'быть',\n",
       " 'было': 'быть',\n",
       " 'в': 'в',\n",
       " 'вернуть': 'вернуть',\n",
       " 'властей': 'власть',\n",
       " 'впоследствии': 'впоследствии',\n",
       " 'выступающей': 'выступать',\n",
       " 'героем': 'герой',\n",
       " 'год': 'год',\n",
       " 'года': 'год',\n",
       " 'годом': 'год',\n",
       " 'году': 'год',\n",
       " 'государства': 'государство',\n",
       " 'декабря': 'декабрь',\n",
       " 'депутаты': 'депутат',\n",
       " 'деятельностью': 'деятельность',\n",
       " 'дипломат': 'дипломат',\n",
       " 'дня': 'день',\n",
       " 'должна': 'должный',\n",
       " 'евреев': 'еврей',\n",
       " 'за': 'за',\n",
       " 'забывать': 'забывать',\n",
       " 'запрещенной': 'запретить',\n",
       " 'заявление': 'заявление',\n",
       " 'звание': 'звание',\n",
       " 'и': 'и',\n",
       " 'из': 'из',\n",
       " 'информационном': 'информационный',\n",
       " 'исполнителей': 'исполнитель',\n",
       " 'их': 'они',\n",
       " 'июле': 'июль',\n",
       " 'к': 'к',\n",
       " 'как': 'как',\n",
       " 'ксенофобией': 'ксенофобия',\n",
       " 'кто': 'кто',\n",
       " 'лидера': 'лидер',\n",
       " 'лидеров': 'лидер',\n",
       " 'месяца': 'месяц',\n",
       " 'мифов': 'миф',\n",
       " 'могу': 'мочь',\n",
       " 'на': 'на',\n",
       " 'написал': 'написать',\n",
       " 'населением': 'население',\n",
       " 'националистов': 'националист',\n",
       " 'национальным': 'национальный',\n",
       " 'начале': 'начало',\n",
       " 'не': 'не',\n",
       " 'независимого': 'независимый',\n",
       " 'непосредственно': 'непосредственно',\n",
       " 'никоим': 'никой',\n",
       " 'о': 'о',\n",
       " 'области': 'область',\n",
       " 'областной': 'областной',\n",
       " 'образом': 'образ',\n",
       " 'обратились': 'обратиться',\n",
       " 'объявить': 'объявить',\n",
       " 'однако': 'однако',\n",
       " 'одним': 'один',\n",
       " 'он': 'он',\n",
       " 'остановит': 'остановить',\n",
       " 'отменено': 'отменить',\n",
       " 'отмечать': 'отмечать',\n",
       " 'период': 'период',\n",
       " 'подрывной': 'подрывной',\n",
       " 'поле': 'поле',\n",
       " 'помогает': 'помогать',\n",
       " 'поможет': 'помочь',\n",
       " 'понять': 'понять',\n",
       " 'посмертно': 'посмертно',\n",
       " 'почитание': 'почитание',\n",
       " 'празднованием': 'празднование',\n",
       " 'предложением': 'предложение',\n",
       " 'президентства': 'президентство',\n",
       " 'президенту': 'президент',\n",
       " 'преступлениях': 'преступление',\n",
       " 'признался': 'признаться',\n",
       " 'признан': 'признать',\n",
       " 'признание': 'признание',\n",
       " 'принимал': 'принимать',\n",
       " 'принял': 'принять',\n",
       " 'пришел': 'прийти',\n",
       " 'провозгласить': 'провозгласить',\n",
       " 'пропагандой': 'пропаганда',\n",
       " 'прославление': 'прославление',\n",
       " 'против': 'против',\n",
       " 'разместил': 'разместить',\n",
       " 'распространение': 'распространение',\n",
       " 'регионе': 'регион',\n",
       " 'решение': 'решение',\n",
       " 'решении': 'решение',\n",
       " 'родился': 'родиться',\n",
       " 'рождения': 'рождение',\n",
       " 'российской': 'российский',\n",
       " 'с': 'с',\n",
       " 'связи': 'связь',\n",
       " 'со': 'с',\n",
       " 'совершенных': 'совершить',\n",
       " 'совет': 'совет',\n",
       " 'создание': 'создание',\n",
       " 'созданных': 'создать',\n",
       " 'страны': 'страна',\n",
       " 'судом': 'суд',\n",
       " 'также': 'также',\n",
       " 'территориях': 'территория',\n",
       " 'тех': 'тот',\n",
       " 'уверены': 'уверить',\n",
       " 'ужасных': 'ужасный',\n",
       " 'узнав': 'узнать',\n",
       " 'украиноязычным': 'украиноязычный',\n",
       " 'украинских': 'украинский',\n",
       " 'участие': 'участие',\n",
       " 'через': 'через',\n",
       " 'что': 'что',\n",
       " 'шок': 'шок',\n",
       " 'это': 'это',\n",
       " 'января': 'январь',\n",
       " '—': '—'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Посол Израиля на Украине Йоэль Лион признался, что пришел в шок, узнав о решении властей Львовской области объявить 2019 год годом лидера запрещенной в России Организации украинских националистов (ОУН) Степана Бандеры. Свое заявление он разместил в Twitter. «Я не могу понять, как прославление тех, кто непосредственно принимал участие в ужасных антисемитских преступлениях, помогает бороться с антисемитизмом и ксенофобией. Украина не должна забывать о преступлениях, совершенных против украинских евреев, и никоим образом не отмечать их через почитание их исполнителей», — написал дипломат. 11 декабря Львовский областной совет принял решение провозгласить 2019 год в регионе годом Степана Бандеры в связи с празднованием 110-летия со дня рождения лидера ОУН (Бандера родился 1 января 1909 года). В июле аналогичное решение принял Житомирский областной совет. В начале месяца с предложением к президенту страны Петру Порошенко вернуть Бандере звание Героя Украины обратились депутаты Верховной Рады. Парламентарии уверены, что признание Бандеры национальным героем поможет в борьбе с подрывной деятельностью против Украины в информационном поле, а также остановит «распространение мифов, созданных российской пропагандой». Степан Бандера (1909-1959) был одним из лидеров Организации украинских националистов, выступающей за создание независимого государства на территориях с украиноязычным населением. В 2010 году в период президентства Виктора Ющенко Бандера был посмертно признан Героем Украины, однако впоследствии это решение было отменено судом. '\n",
    "\n",
    "natasha_lemmatize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rck5OVqhLVSA"
   },
   "source": [
    "### mystem vs. pymorphy vs. natasha\n",
    "\n",
    "1) *Мы надеемся, что вы пользуетесь линуксом*, но mystem работает невероятно медленно под windows на больших текстах.\n",
    "\n",
    "2) *Снятие омонимии*. Mystem умеет снимать омонимию по контексту (хотя не всегда преуспевает), pymorphy2 берет на вход одно слово и соответственно вообще не умеет дизамбигуировать по контексту, natasha тоже с этим тоже не справляется успешно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kH2GQ4ddLVSB"
   },
   "outputs": [],
   "source": [
    "homonym1 = 'За время обучения я прослушал больше сорока курсов.'\n",
    "homonym2 = 'Сорока своровала блестящее украшение со стола.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwF-XsjeI3eX",
    "outputId": "34e9f131-3af5-4a87-9a8c-aa51d6e076ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analysis': [{'lex': 'сорок', 'wt': 0.8710292578, 'gr': 'NUM=(пр|дат|род|твор)'}], 'text': 'сорока'}\n",
      "{'analysis': [{'lex': 'сорока', 'wt': 0.1210970059, 'gr': 'S,жен,од=им,ед'}], 'text': 'Сорока'}\n"
     ]
    }
   ],
   "source": [
    "mystem_analyzer = Mystem() # инициализирую объект с дефолтными параметрами\n",
    "\n",
    "print(mystem_analyzer.analyze(homonym1)[-5])\n",
    "print(mystem_analyzer.analyze(homonym2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t9jezRVlFmDo",
    "outputId": "e2224fd9-09e3-428e-fa6a-1af94dcb2ca8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'За': 'за', 'время': 'время', 'обучения': 'обучение', 'я': 'я', 'прослушал': 'прослушать', 'больше': 'большой', 'сорока': 'сорок', 'курсов': 'курс', '.': '.'}\n"
     ]
    }
   ],
   "source": [
    "print(natasha_lemmatize(homonym1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SXjGBQPoI9gl",
    "outputId": "049fe8af-e0c5-499f-cc10-6d05b047a168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Сорока': 'сорок', 'своровала': 'своровать', 'блестящее': 'блестящий', 'украшение': 'украшение', 'со': 'с', 'стола': 'стол', '.': '.'}\n"
     ]
    }
   ],
   "source": [
    "print(natasha_lemmatize(homonym2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aP5qFnilLVSI"
   },
   "source": [
    "## Словарь, закон Ципфа и закон Хипса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1umtd3OLVSI"
   },
   "source": [
    "Закон Ципфа -- эмпирическая закономерность: если все слова корпуса текста упорядочить по убыванию частоты их использования, то частота n-го слова в таком списке окажется приблизительно обратно пропорциональной его порядковому номеру n. Иными словами, частотность слов убывает очень быстро."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "lY0cWJ7eLVSJ"
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vIjqSVjpLVSL",
    "outputId": "a75ec748-ab21-4bd0-cd41-5a9fa8362b22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2870536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['first_timee', 'хоть', 'я', 'и', 'школота', 'но', 'поверь', 'у', 'нас', 'то']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [token for tweet in df.text for token in word_tokenize(tweet) if token not in punctuation]\n",
    "print(len(corpus))\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "_oWC7NpkLVSO",
    "outputId": "965b9fbd-6328-4c13-f20f-cd3714d1adb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('не', 69472),\n",
       " ('и', 55166),\n",
       " ('в', 52902),\n",
       " ('я', 52818),\n",
       " ('RT', 38070),\n",
       " ('на', 35759),\n",
       " ('http', 32998),\n",
       " ('что', 31541),\n",
       " ('с', 27217),\n",
       " ('а', 26860)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict = Counter(corpus)\n",
    "freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
    "list(freq_dict_sorted)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "FrPkce0SLVSQ",
    "outputId": "d2ab5675-433a-480a-90ee-fa5dd9890922"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "first_100_freqs = [freq for word, freq in freq_dict_sorted[:100]]\n",
    "plt.plot(first_100_freqs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_N5V_K-LVSU"
   },
   "source": [
    "Закон Хипса -- обратная сторона закона Ципфа. Он описывает, что чем больше корпус, тем меньше новых слов добавляется с добавлением новых текстов. В какой-то момент корпус насыщается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dw0GieJSMU-O"
   },
   "source": [
    "## Задание 1.\n",
    "\n",
    "**Задание**: обучите три классификатора: \n",
    "\n",
    "1) на токенах с высокой частотой \n",
    "\n",
    "2) на токенах со средней частотой \n",
    "\n",
    "3) на токенах с низкой частотой\n",
    "\n",
    "Сравните полученные результаты, оцените какие токены наиболее важные для классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_freq = freq_dict_sorted[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "QUQ6kAgPMqNn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['не',\n",
       " 'и',\n",
       " 'в',\n",
       " 'я',\n",
       " 'RT',\n",
       " 'на',\n",
       " 'http',\n",
       " 'что',\n",
       " 'с',\n",
       " 'а',\n",
       " '...',\n",
       " 'меня',\n",
       " 'у',\n",
       " 'как',\n",
       " 'так',\n",
       " 'D',\n",
       " 'это',\n",
       " 'мне',\n",
       " 'все',\n",
       " 'ты']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def freq_dict_to_corpus(freq_dict):\n",
    "    corpus = []\n",
    "    for i in range(len(freq_dict)):\n",
    "        corpus.append(freq_dict[i][0])\n",
    "    return corpus\n",
    "\n",
    "\n",
    "high_freq_corpus = freq_dict_to_corpus(high_freq)\n",
    "high_freq_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid_freq_corpus = freq_dict_to_corpus(freq_dict_sorted[20:75])\n",
    "len(mid_freq_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4500"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_freq_corpus = freq_dict_to_corpus(freq_dict_sorted[75:4575])\n",
    "len(low_freq_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['я', 'на', 'что', 'не']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_and_tok(text):\n",
    "    return [word.lower() for word in word_tokenize(text)]\n",
    "\n",
    "\n",
    "def word_tokenize_isolated(text, corpus):\n",
    "    return [word for word in preprocess_and_tok(text) if word in corpus]\n",
    "\n",
    "\n",
    "def word_tokenize_high_freq(text):\n",
    "    return word_tokenize_isolated(text, high_freq_corpus)\n",
    "\n",
    "\n",
    "def word_tokenize_mid_freq(text):\n",
    "    return word_tokenize_isolated(text, mid_freq_corpus)\n",
    "\n",
    "\n",
    "def word_tokenize_low_freq(text):\n",
    "    return word_tokenize_isolated(text, low_freq_corpus)\n",
    "\n",
    "\n",
    "word_tokenize_high_freq('Я ни на что не годен')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- High term frequency tokenizer ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.55      0.60      0.57     25785\n",
      "    positive       0.64      0.59      0.61     30924\n",
      "\n",
      "    accuracy                           0.59     56709\n",
      "   macro avg       0.59      0.59      0.59     56709\n",
      "weighted avg       0.60      0.59      0.59     56709\n",
      "\n",
      "--- Middle term frequency tokenizer ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.44      0.60      0.50     20514\n",
      "    positive       0.71      0.56      0.63     36195\n",
      "\n",
      "    accuracy                           0.57     56709\n",
      "   macro avg       0.57      0.58      0.57     56709\n",
      "weighted avg       0.61      0.57      0.58     56709\n",
      "\n",
      "--- Low term frequency tokenizer ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.72      0.69     25758\n",
      "    positive       0.75      0.69      0.72     30951\n",
      "\n",
      "    accuracy                           0.70     56709\n",
      "   macro avg       0.70      0.70      0.70     56709\n",
      "weighted avg       0.71      0.70      0.70     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizers = [\n",
    "    (word_tokenize_high_freq, 'High'),\n",
    "    (word_tokenize_mid_freq, 'Middle'),\n",
    "    (word_tokenize_low_freq, 'Low')\n",
    "]\n",
    "\n",
    "for tok, name in tokenizers:\n",
    "    clf = LogisticRegression(random_state=21, max_iter=10000)\n",
    "    vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=tok)\n",
    "    bow = vec.fit_transform(x_train)\n",
    "    clf.fit(bow, y_train)\n",
    "    pred = clf.predict(vec.transform(x_test))\n",
    "    print(f'--- {name} term frequency tokenizer ---')\n",
    "    print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mV3fmzp-LVSU"
   },
   "source": [
    "## О важности эксплоративного анализа\n",
    "\n",
    "Но иногда пунктуация бывает и не шумом -- главное отталкиваться от задачи. Что будет если вообще не убирать пунктуацию?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "qjkMxK9VLVSV",
    "outputId": "dfea56d5-4d92-4862-9788-29c8c8db29ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00     28110\n",
      "    positive       1.00      1.00      1.00     28599\n",
      "\n",
      "    accuracy                           1.00     56709\n",
      "   macro avg       1.00      1.00      1.00     56709\n",
      "weighted avg       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2fRbUAvLVSX"
   },
   "source": [
    "Шок! Стоило оставить пунктуацию -- и все метрики равны 1. Как это получилось? Среди неё были очень значимые токены (как вы думаете, какие?). Найдите фичи с самыми большими коэффициэнтами:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.\n",
    "\n",
    "найти фичи с наибольшей значимостью, и вывести их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3804, -7.361441114382496, 6.961584811505197)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = clf.coef_[0]\n",
    "imp_min = importance.min()\n",
    "imp_max = importance.max()\n",
    "len(importance), imp_min, imp_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Name</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>^_^</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>х</td>\n",
       "      <td>0.811612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>обожаю</td>\n",
       "      <td>0.760712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>ахаха</td>\n",
       "      <td>0.757581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>приятно</td>\n",
       "      <td>0.755556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>грустно</td>\n",
       "      <td>0.178620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>печально</td>\n",
       "      <td>0.173514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>to_over_kill</td>\n",
       "      <td>0.127539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>обидно</td>\n",
       "      <td>0.091097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-/</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3804 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature Name  Importance\n",
       "81             ^_^    1.000000\n",
       "3547             х    0.811612\n",
       "1925        обожаю    0.760712\n",
       "181          ахаха    0.757581\n",
       "2540       приятно    0.755556\n",
       "...            ...         ...\n",
       "641        грустно    0.178620\n",
       "2153      печально    0.173514\n",
       "125   to_over_kill    0.127539\n",
       "1917        обидно    0.091097\n",
       "2               -/    0.000000\n",
       "\n",
       "[3804 rows x 2 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def invlerp(a, b, v):\n",
    "    return (v - a) / (b - a)\n",
    "\n",
    "\n",
    "def normalize_importance(value):\n",
    "    return invlerp(imp_min, imp_max, value)\n",
    "\n",
    "\n",
    "importance_df = pd.DataFrame()\n",
    "importance_df['Feature Name'] = vec.get_feature_names_out()\n",
    "importance_df['Importance'] = importance\n",
    "importance_df['Importance'] = \\\n",
    "    importance_df['Importance'].apply(normalize_importance)\n",
    "importance_df.sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vtAyItvLVSb"
   },
   "source": [
    "Посмотрим, как один из супер-значительных токенов справится с классификацией безо всякого машинного обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "uqH07o-7LVSc",
    "outputId": "fad0a24a-98ee-4f84-8782-495548eb0fb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.50      0.67     56503\n",
      "    positive       0.01      1.00      0.01       206\n",
      "\n",
      "    accuracy                           0.50     56709\n",
      "   macro avg       0.50      0.75      0.34     56709\n",
      "weighted avg       1.00      0.50      0.66     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cool_token = '^_^'\n",
    "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5THCOjMLVSg"
   },
   "source": [
    "## Символьные n-граммы\n",
    "\n",
    "Теперь в качестве фичей используем, например, униграммы символов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "AIUwDOabLVSh",
    "outputId": "54f129b1-994f-448e-e861-1912b4a21cdc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/nn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      1.00     28023\n",
      "    positive       1.00      0.99      1.00     28686\n",
      "\n",
      "    accuracy                           1.00     56709\n",
      "   macro avg       1.00      1.00      1.00     56709\n",
      "weighted avg       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_E0uPpgLVSj"
   },
   "source": [
    "В общем-то, теперь уже понятно, почему на этих данных здесь 1. Так или инчае, на символах классифицировать тоже можно: для некторых задач (например, для определения языка) фичи-символьные n-граммы решительно рулят.\n",
    "\n",
    "Ещё одна замечательная особенность фичей-символов: токенизация и лемматизация не нужна, можно использовать такой подход для языков, у которых нет готвых анализаторов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3.\n",
    "\n",
    "1) сравнить count/tf-idf/hashing векторайзеры/полносвязанную сетку (построить classification_report)\n",
    "\n",
    "2) подобрать оптимальный размер для hashing векторайзера \n",
    "\n",
    "3) убедиться что для сетки нет переобучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Count vectorizer ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.41      0.60      0.49     19127\n",
      "    positive       0.73      0.56      0.63     37582\n",
      "\n",
      "    accuracy                           0.57     56709\n",
      "   macro avg       0.57      0.58      0.56     56709\n",
      "weighted avg       0.63      0.57      0.59     56709\n",
      "\n",
      "--- TF-IDF vectorizer ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.44      0.60      0.50     20514\n",
      "    positive       0.71      0.56      0.63     36195\n",
      "\n",
      "    accuracy                           0.57     56709\n",
      "   macro avg       0.57      0.58      0.57     56709\n",
      "weighted avg       0.61      0.57      0.58     56709\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/nn/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Hashing vectorizer ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.39      0.52      0.45     21108\n",
      "    positive       0.65      0.52      0.58     35601\n",
      "\n",
      "    accuracy                           0.52     56709\n",
      "   macro avg       0.52      0.52      0.51     56709\n",
      "weighted avg       0.55      0.52      0.53     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = word_tokenize_mid_freq\n",
    "ngram_range = (1, 1)\n",
    "\n",
    "vectorizers = [\n",
    "    (CountVectorizer(ngram_range=ngram_range, tokenizer=tokenizer), 'Count'),\n",
    "    (TfidfVectorizer(ngram_range=ngram_range, tokenizer=tokenizer), 'TF-IDF'),\n",
    "    (HashingVectorizer(ngram_range=ngram_range, n_features=4, tokenizer=tokenizer), 'Hashing')\n",
    "]\n",
    "\n",
    "for vec, name in vectorizers:\n",
    "    clf = LogisticRegression(random_state=21, max_iter=10000)\n",
    "    bow = vec.fit_transform(x_train)\n",
    "    clf.fit(bow, y_train)\n",
    "    pred = clf.predict(vec.transform(x_test))\n",
    "    print(f'--- {name} vectorizer ---')\n",
    "    print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбор количества признаков для Hashing векторизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 4, score: 0.5765998908722426\n",
      "n_features: 8, score: 0.5834941321608198\n",
      "n_features: 12, score: 0.6265949049156799\n",
      "n_features: 18, score: 0.6203820751367092\n",
      "n_features: 24, score: 0.6109745364047466\n",
      "n_features: 48, score: 0.6221036030571394\n",
      "\n",
      "Best n_features: 12, best score: 0.6265949049156799\n"
     ]
    }
   ],
   "source": [
    "n_features_list = [4, 8, 12, 18, 24, 48]\n",
    "best_score = 0\n",
    "best_n_feats = 0\n",
    "\n",
    "for n_feats in n_features_list:\n",
    "    vec = HashingVectorizer(ngram_range=(1, 1), n_features=n_feats, tokenizer=word_tokenize_mid_freq)\n",
    "    clf = LogisticRegression(random_state=21, max_iter=10000)\n",
    "    bow = vec.fit_transform(x_train)\n",
    "    clf.fit(bow, y_train)\n",
    "    pred = clf.predict(vec.transform(x_test))\n",
    "    score = f1_score(pred, y_test, pos_label='positive')\n",
    "    if(score > best_score):\n",
    "        best_score = score\n",
    "        best_n_feats = n_feats\n",
    "    print(f'n_features: {n_feats}, score: {score}')\n",
    "\n",
    "print(f'\\nBest n_features: {best_n_feats}, best score: {best_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Полносвязная нейросеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feats = 12\n",
    "vec = HashingVectorizer(ngram_range=(1, 1), n_features=n_feats, tokenizer=word_tokenize_mid_freq)\n",
    "bow_train = vec.fit_transform(x_train).toarray()\n",
    "bow_test = vec.transform(x_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_int(y):\n",
    "    return (y == 'positive').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((bow_train, labels_to_int(y_train))).batch(512)\n",
    "valid_data = tf.data.Dataset.from_tensor_slices((bow_test, labels_to_int(y_test))).batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dropout(0.2),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 09:43:37.906995: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333/333 [==============================] - ETA: 0s - loss: 0.6887 - accuracy: 0.4986"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 09:43:40.517996: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333/333 [==============================] - 4s 8ms/step - loss: 0.6887 - accuracy: 0.4986 - val_loss: 0.6863 - val_accuracy: 0.5018\n",
      "Epoch 2/5\n",
      "333/333 [==============================] - 3s 8ms/step - loss: 0.6875 - accuracy: 0.5000 - val_loss: 0.6860 - val_accuracy: 0.5022\n",
      "Epoch 3/5\n",
      "333/333 [==============================] - 3s 8ms/step - loss: 0.6873 - accuracy: 0.5003 - val_loss: 0.6859 - val_accuracy: 0.5025\n",
      "Epoch 4/5\n",
      "333/333 [==============================] - 3s 8ms/step - loss: 0.6871 - accuracy: 0.5005 - val_loss: 0.6858 - val_accuracy: 0.5026\n",
      "Epoch 5/5\n",
      "333/333 [==============================] - 3s 8ms/step - loss: 0.6870 - accuracy: 0.5008 - val_loss: 0.6857 - val_accuracy: 0.5027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b7642ef0>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, validation_data=valid_data, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  26/1773 [..............................] - ETA: 11s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 09:44:03.591177: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1773/1773 [==============================] - 6s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.17631052],\n",
       "       [-0.20230967],\n",
       "       [-0.27156734],\n",
       "       ...,\n",
       "       [ 0.0364413 ],\n",
       "       [-0.02053654],\n",
       "       [ 0.06273501]], dtype=float32)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(vec.transform(x_test))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.50      0.66     55739\n",
      "           1       0.02      0.68      0.04       970\n",
      "\n",
      "    accuracy                           0.50     56709\n",
      "   macro avg       0.51      0.59      0.35     56709\n",
      "weighted avg       0.97      0.50      0.65     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report((pred > 0.5).astype(int), labels_to_int(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание\n",
    "\n",
    "все материалы для выполения дз в `sem2.ipynb`\n",
    "\n",
    "\n",
    "### Задание 1.\n",
    "\n",
    "**Задание**: обучите три классификатора: \n",
    "\n",
    "1) на токенах с высокой частотой \n",
    "\n",
    "2) на токенах со средней частотой \n",
    "\n",
    "3) на токенах с низкой частотой\n",
    "\n",
    "\n",
    "Сравните полученные результаты, оцените какие токены наиболее важные для классификации.\n",
    "\n",
    "\n",
    "### Задание 2.\n",
    "\n",
    "найти фичи с наибольшей значимостью, и вывести их\n",
    "\n",
    "\n",
    "### Задание 3.\n",
    "\n",
    "1) сравнить count/tf-idf/hashing векторайзеры/полносвязанную сетку (построить classification_report)\n",
    "\n",
    "2) подобрать оптимальный размер для hashing векторайзера \n",
    "\n",
    "3) убедиться что для сетки нет переобучения"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "gJABxhalLVQu",
    "IaQMCGHFLVQ6",
    "5AJk1B39LVRP",
    "RJlvqWuALVRs",
    "rck5OVqhLVSA",
    "mV3fmzp-LVSU",
    "H5THCOjMLVSg",
    "02s2Vh7MLVSj",
    "b1khxRFDLVSm",
    "sfUmWcAQLVSt",
    "BxvtN-3zLVS5",
    "gyrHhYkgLVTB"
   ],
   "name": "sem1_intro_common.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "3af7e179898fb99d78969cca94508015726394a06defd0be323cbf435423c41d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('nn': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
