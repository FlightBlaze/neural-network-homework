{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –î–æ–º–∞—à–Ω—è—è —Ä–∞–±–æ—Ç–∞\n",
    "\n",
    "–î–∞–Ω–Ω—ã–µ –±–µ—Ä–µ–º –æ—Ç—ã–∑—ã–≤—ã –∑–∞ –ª–µ—Ç–æ\n",
    "–ù–∞ –≤–µ–±–∏–Ω–∞—Ä–µ –º—ã –≥–æ–≤–æ—Ä–∏–ª–∏, —á—Ç–æ –¥–æ–ª–≥–æ–µ –≤—Ä–µ–º—è CNN –∏ RNN –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –±—ã–ª–∏ –∫–æ–Ω—É—Ä–∏—Ä—É–µ—â–∏–º–∏ –≤—ã—è—Å–Ω–∏—Ç—å –∫–∞–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –±–æ–ª—å—à–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –Ω–∞—à–µ–π –∑–∞–¥–∞—á–∏ \n",
    "1. –ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Å–≤—ë—Ä—Ç–æ—á–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã \n",
    "2. –ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å RNN\n",
    "3. –ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Å–æ–≤–º–µ—Å—Ç–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã CNN -> RNN –∏–ª–∏ (RNN -> CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in /opt/homebrew/Caskroom/miniforge/base/envs/nn/lib/python3.10/site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../homework7/–æ—Ç–∑—ã–≤—ã –∑–∞ –ª–µ—Ç–æ.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>–í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–æ –≤—Å–µ</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>–°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å—ë —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º üëçüëçüëç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>–£ –º–µ–Ω—è —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ —á–µ—Ç–∫–æ. –í –æ—Ç–ª–∏—á–∏–∏ –æ—Ç –±–∞–Ω–∫–æ–º...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å –≤—Å–µ —Ö–æ—Ä–æ—à–æüëç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å–µ –æ–∫!</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –∫—Ä–æ–º–µ —Ç–æ–≥–æ —á—Ç–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –Ω–µ–ª—å...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>–ù–µ —Å—Ç–∞—Ä—Ç—É–µ—Ç –±–µ–∑ –¥–æ—Å—Ç—É–ø–∞ –∫ gps, sms, –∑–≤–æ–Ω–∫–∞–º –∏ ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–æ, –ø–æ–¥–≤–∏—Å–∞–Ω–∏...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rating                                            Content        Date\n",
       "0        5                                     It just works!  2017-08-14\n",
       "1        4  –í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...  2017-08-14\n",
       "2        5                                        –û—Ç–ª–∏—á–Ω–æ –≤—Å–µ  2017-08-14\n",
       "3        5  –°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...  2017-08-14\n",
       "4        5                     –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.  2017-08-14\n",
       "5        5                                –í—Å—ë —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º üëçüëçüëç  2017-08-14\n",
       "6        5                          –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.  2017-08-14\n",
       "7        5                                     –í—Å–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç  2017-08-14\n",
       "8        5  –£ –º–µ–Ω—è —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ —á–µ—Ç–∫–æ. –í –æ—Ç–ª–∏—á–∏–∏ –æ—Ç –±–∞–Ω–∫–æ–º...  2017-08-14\n",
       "9        5                                  –û—á–µ–Ω—å –≤—Å–µ —Ö–æ—Ä–æ—à–æüëç  2017-08-14\n",
       "10       5                                            –í—Å–µ –æ–∫!  2017-08-14\n",
       "11       5  –í—Å–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –∫—Ä–æ–º–µ —Ç–æ–≥–æ —á—Ç–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –Ω–µ–ª—å...  2017-08-14\n",
       "12       2  –ù–µ —Å—Ç–∞—Ä—Ç—É–µ—Ç –±–µ–∑ –¥–æ—Å—Ç—É–ø–∞ –∫ gps, sms, –∑–≤–æ–Ω–∫–∞–º –∏ ...  2017-08-14\n",
       "13       5  –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–æ, –ø–æ–¥–≤–∏—Å–∞–Ω–∏...  2017-08-14\n",
       "14       5                                       –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ  2017-08-14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    14586\n",
       "1     2276\n",
       "4     2138\n",
       "3      911\n",
       "2      748\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20659, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import pymorphy2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['—Å—ä–µ—Å—Ç—å', '–µ—â—ë', '–º—è–≥–∫–∏–π', '—Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π', '–±—É–ª–∫–∞', '–≤—ã–ø–∏—Ç—å', '—á–∞–π']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "stopwords_list = stopwords.words('russian')\n",
    "punct = set(punctuation)\n",
    "\n",
    "def tokenize_and_preprocess(text):\n",
    "    if type(text) is not str:\n",
    "        return []\n",
    "    # txt = \"\".join(c for c in text if c not in punct)\n",
    "    txt = text\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\s–Ω–µ\", \"–Ω–µ\", txt)\n",
    "    words = word_tokenize(txt)\n",
    "    lemmas = [morph.parse(w)[0].normal_form for w in words]\n",
    "    return [w for w in lemmas if not w in stopwords_list and w.isalpha()]\n",
    "\n",
    "tokenize_and_preprocess('–°—ä–µ—à—å –µ—â–µ —ç—Ç–∏—Ö –º—è–≥–∫–∏—Ö —Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–∏—Ö –±—É–ª–æ–∫, –¥–∞ –≤—ã–ø–µ–π –∂–µ —á–∞—é!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "      <th>Prepared_Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>[it, just, works]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>–í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>[—Ü–µ–ª–æ–µ, —É–¥–æ–±–Ω–æ–Ω–æ–π, –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, –º–∏–Ω—É—Å, —Ö–æ—Ç–µ—Ç—å, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–æ –≤—Å–µ</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>[–æ—Ç–ª–∏—á–Ω–æ, –≤—Å—ë]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>–°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>[—Å—Ç–∞—Ç—å, –∑–∞–≤–∏—Å–∞—Ç—å, —Ä–∞–±–æ—Ç–∞, –∞–Ω—Ç–∏–≤–∏—Ä—É—Å, –¥–∞–ª—ë–∫–∏–π, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>[–æ—á–µ–Ω—å, —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞—Ç—å, –±—ã—Å—Ç—Ä–æ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date  \\\n",
       "0       5                                     It just works!  2017-08-14   \n",
       "1       4  –í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...  2017-08-14   \n",
       "2       5                                        –û—Ç–ª–∏—á–Ω–æ –≤—Å–µ  2017-08-14   \n",
       "3       5  –°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...  2017-08-14   \n",
       "4       5                     –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.  2017-08-14   \n",
       "\n",
       "                                    Prepared_Content  \n",
       "0                                  [it, just, works]  \n",
       "1  [—Ü–µ–ª–æ–µ, —É–¥–æ–±–Ω–æ–Ω–æ–π, –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, –º–∏–Ω—É—Å, —Ö–æ—Ç–µ—Ç—å, ...  \n",
       "2                                     [–æ—Ç–ª–∏—á–Ω–æ, –≤—Å—ë]  \n",
       "3  [—Å—Ç–∞—Ç—å, –∑–∞–≤–∏—Å–∞—Ç—å, —Ä–∞–±–æ—Ç–∞, –∞–Ω—Ç–∏–≤–∏—Ä—É—Å, –¥–∞–ª—ë–∫–∏–π, ...  \n",
       "4                  [–æ—á–µ–Ω—å, —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞—Ç—å, –±—ã—Å—Ç—Ä–æ]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Prepared_Content'] = df['Content'].apply(tokenize_and_preprocess)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tokens = []\n",
    "for i in range(len(df_train)):\n",
    "    corpus_tokens += df_train[\"Prepared_Content\"].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "max_words = 5000\n",
    "max_len = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__–°–æ–∑–¥–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "dist = FreqDist(corpus_tokens)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',\n",
       " '–≤—Å—ë',\n",
       " '–æ—á–µ–Ω—å',\n",
       " '—É–¥–æ–±–Ω–æ',\n",
       " '—Ä–∞–±–æ—Ç–∞—Ç—å',\n",
       " '—É–¥–æ–±–Ω—ã–π',\n",
       " '–æ—Ç–ª–∏—á–Ω–æ',\n",
       " '—Å–ø–∞—Å–∏–±–æ',\n",
       " '—Ö–æ—Ä–æ—à–∏–π',\n",
       " '–Ω—Ä–∞–≤–∏—Ç—å—Å—è']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_filtered_top[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sequence(tokens, maxlen):\n",
    "    result = []\n",
    "    for word in tokens:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "    padding = [0] * (maxlen-len(result))\n",
    "    return padding + result[-maxlen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray([text_to_sequence(text, max_len) for text in df_train[\"Prepared_Content\"]], dtype=np.int32)\n",
    "X_val = np.asarray([text_to_sequence(text, max_len) for text in df_val[\"Prepared_Content\"]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(df_train['Rating'])\n",
    "y_val = label_encoder.fit_transform(df_val['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 512\n",
    "print_batch_n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_train_classifier(model, epochs=20):\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model.fit(X_train, y_train,\n",
    "                     batch_size=batch_size,\n",
    "                     epochs=epochs,\n",
    "                     verbose=1,\n",
    "                     validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–∞—è —Å–µ—Ç—å\n",
    "\n",
    "–¢–∞–∫ –∫–∞–∫ —É –º–µ–Ω—è LSTM –ø–æ—á–µ–º—É-—Ç–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ GPU (–¥–æ–ª–≥–æ –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è), –±—É–¥—É –æ–±—É—á–∞—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω—É —ç–ø–æ—Ö—É"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 20:38:50.272601: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - ETA: 0s - loss: 1.3992 - accuracy: 0.6819"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 20:40:46.470959: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 120s 4s/step - loss: 1.3992 - accuracy: 0.6819 - val_loss: 0.9883 - val_accuracy: 0.7113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x30dea3310>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn = keras.models.Sequential([\n",
    "    keras.layers.Embedding(\n",
    "        input_dim=max_words, output_dim=128,\n",
    "        input_length=max_len, mask_zero=True),\n",
    "    keras.layers.LSTM(80, recurrent_dropout=0.2),\n",
    "    keras.layers.Dense(25, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(num_classes),\n",
    "    keras.layers.Activation('softmax'),\n",
    "])\n",
    "compile_train_classifier(model_rnn, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –°–≤–µ—Ä—Ç–æ—á–Ω–∞—è —Å–µ—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 20:41:12.845774: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 5s 134ms/step - loss: 1.0653 - accuracy: 0.7045 - val_loss: 0.8411 - val_accuracy: 0.7195\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 20:41:17.091223: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 3s 108ms/step - loss: 0.7494 - accuracy: 0.7504 - val_loss: 0.6510 - val_accuracy: 0.7741\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 0.6271 - accuracy: 0.7815 - val_loss: 0.6170 - val_accuracy: 0.7835\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 4s 119ms/step - loss: 0.5698 - accuracy: 0.8000 - val_loss: 0.6106 - val_accuracy: 0.7868\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 4s 120ms/step - loss: 0.5201 - accuracy: 0.8192 - val_loss: 0.6076 - val_accuracy: 0.7905\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 0.4732 - accuracy: 0.8385 - val_loss: 0.6165 - val_accuracy: 0.7886\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 3s 108ms/step - loss: 0.4275 - accuracy: 0.8595 - val_loss: 0.6382 - val_accuracy: 0.7833\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 4s 122ms/step - loss: 0.3828 - accuracy: 0.8767 - val_loss: 0.6608 - val_accuracy: 0.7839\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 3s 102ms/step - loss: 0.3393 - accuracy: 0.8949 - val_loss: 0.6931 - val_accuracy: 0.7742\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 3s 101ms/step - loss: 0.3013 - accuracy: 0.9127 - val_loss: 0.7317 - val_accuracy: 0.7702\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 3s 102ms/step - loss: 0.2698 - accuracy: 0.9238 - val_loss: 0.7840 - val_accuracy: 0.7764\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 4s 120ms/step - loss: 0.2449 - accuracy: 0.9310 - val_loss: 0.8296 - val_accuracy: 0.7665\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 0.2239 - accuracy: 0.9377 - val_loss: 0.8777 - val_accuracy: 0.7682\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 0.2058 - accuracy: 0.9428 - val_loss: 0.9103 - val_accuracy: 0.7607\n",
      "Epoch 15/20\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 0.1934 - accuracy: 0.9457 - val_loss: 0.9586 - val_accuracy: 0.7584\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 3s 101ms/step - loss: 0.1840 - accuracy: 0.9468 - val_loss: 1.0020 - val_accuracy: 0.7524\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 0.1739 - accuracy: 0.9508 - val_loss: 1.0551 - val_accuracy: 0.7590\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 3s 100ms/step - loss: 0.1677 - accuracy: 0.9524 - val_loss: 1.0799 - val_accuracy: 0.7533\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 3s 100ms/step - loss: 0.1611 - accuracy: 0.9529 - val_loss: 1.1157 - val_accuracy: 0.7512\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 3s 99ms/step - loss: 0.1567 - accuracy: 0.9553 - val_loss: 1.1519 - val_accuracy: 0.7524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f41b87c0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conv = keras.models.Sequential([\n",
    "    keras.layers.Embedding(\n",
    "        input_dim=max_words, output_dim=128,\n",
    "        input_length=max_len, mask_zero=True),\n",
    "    keras.layers.Conv1D(128, 7),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.GlobalMaxPool1D(),\n",
    "    keras.layers.Dense(25),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(num_classes),\n",
    "    keras.layers.Activation('softmax'),\n",
    "])\n",
    "compile_train_classifier(model_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM + CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 20:51:30.182550: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - ETA: 0s - loss: 1.4322 - accuracy: 0.6837"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 20:53:40.879703: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 135s 4s/step - loss: 1.4322 - accuracy: 0.6837 - val_loss: 1.0970 - val_accuracy: 0.7121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3597f36a0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn_cnn = keras.models.Sequential([\n",
    "    keras.layers.Embedding(\n",
    "        input_dim=max_words, output_dim=128,\n",
    "        input_length=max_len, mask_zero=True),\n",
    "    keras.layers.LSTM(80, recurrent_dropout=0.2),\n",
    "    keras.layers.Reshape((80, 1)),\n",
    "    keras.layers.Conv1D(128, 7),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.GlobalMaxPool1D(),\n",
    "    keras.layers.Dense(25, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(num_classes),\n",
    "    keras.layers.Activation('softmax'),\n",
    "])\n",
    "compile_train_classifier(model_rnn_cnn, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 20:42:20.954620: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚≠ê –ì–æ–≤–Ω–æ —Ç—É–ø–æ–µ –£–¥–∞–ª—è—é!\n",
      "‚≠ê‚≠ê –ì–æ–≤–Ω–æ.\n",
      "‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê –û—Ç–ª–∏—á–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ! –í—Å–µ —Å—É–ø–µ—Ä!\n",
      "‚≠ê‚≠ê‚≠ê‚≠ê –ù—É –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –Ω–æ —É –º–µ–Ω—è —Ö–æ–ª–æ–¥—å–Ω–∏–∫ –æ—Ç –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞ —Å–ª–æ–º–∞–ª—Å—è\n"
     ]
    }
   ],
   "source": [
    "def repeat_str(text, n):\n",
    "    ret = ''\n",
    "    for i in range(n):\n",
    "        ret += text\n",
    "    return ret\n",
    "\n",
    "\n",
    "def predict(text):\n",
    "    rating = np.argmax(\n",
    "        model_conv.predict(\n",
    "            np.array([\n",
    "                text_to_sequence(tokenize_and_preprocess(text), max_len)\n",
    "            ]), verbose=0\n",
    "        )\n",
    "    ) + 1\n",
    "    return rating\n",
    "\n",
    "\n",
    "def predict_print(text):\n",
    "    rating = predict(text)\n",
    "    print(repeat_str('‚≠ê', rating) + ' ' + text)\n",
    "\n",
    "\n",
    "predict_print('–ì–æ–≤–Ω–æ —Ç—É–ø–æ–µ –£–¥–∞–ª—è—é!')\n",
    "predict_print('–ì–æ–≤–Ω–æ.')\n",
    "predict_print('–û—Ç–ª–∏—á–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ! –í—Å–µ —Å—É–ø–µ—Ä!')\n",
    "predict_print('–ù—É –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –Ω–æ —É –º–µ–Ω—è —Ö–æ–ª–æ–¥—å–Ω–∏–∫ –æ—Ç –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞ —Å–ª–æ–º–∞–ª—Å—è')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3af7e179898fb99d78969cca94508015726394a06defd0be323cbf435423c41d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('nn': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
